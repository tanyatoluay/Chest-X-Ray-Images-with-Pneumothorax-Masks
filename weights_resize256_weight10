{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":871956,"sourceType":"datasetVersion","datasetId":461757}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zahnbuerste19/cvfbi-project-weighted-unet-version-new-dice?scriptVersionId=254822942\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# SIIM-ACR Pneumothorax Segmentation\n\n**Class:** Computer Vision for Biomedical Images\n\n**Date:** Summer semester 2025\n\n**Group:** Julia Lapucha & Tanya Toluay\n","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:10:24.312484Z","iopub.execute_input":"2025-07-17T09:10:24.312737Z","iopub.status.idle":"2025-07-17T09:10:25.317023Z","shell.execute_reply.started":"2025-07-17T09:10:24.312715Z","shell.execute_reply":"2025-07-17T09:10:25.316476Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Introduction\n### Descriptive statistics","metadata":{}},{"cell_type":"code","source":"# Paths to the dataset\ncsv_path = '/kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv'\nmask_dir = '/kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks'\n\n# Load CSV metadata\ndf = pd.read_csv(csv_path)\n\n# Add mask path and check if mask file exists\ndf['mask_path'] = df['new_filename'].apply(lambda x: os.path.join(mask_dir, x))\ndf['mask_exists'] = df['mask_path'].apply(os.path.exists)\n\n# Function to calculate mask area\ndef get_mask_area(mask_path):\n    if os.path.exists(mask_path):\n        mask = np.array(Image.open(mask_path))\n        return np.sum(mask > 0)\n    else:\n        return 0\n\n# Calculate mask areas for all images\ndf['mask_area'] = df['mask_path'].apply(get_mask_area)\n\n# Summary stats\ntotal_images = len(df)\nwith_pneumo = df['has_pneumo'].sum()\nwithout_pneumo = total_images - with_pneumo\n\nprint(f\"Total images: {total_images}\")\nprint(f\"Images with pneumothorax (CSV label): {with_pneumo}\")\nprint(f\"Images without pneumothorax (CSV label): {without_pneumo}\")\n\nprint(f\"Images with mask file: {df['mask_exists'].sum()}\")\nprint(f\"Images without mask file: {total_images - df['mask_exists'].sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:10:25.318349Z","iopub.execute_input":"2025-07-17T09:10:25.319299Z","iopub.status.idle":"2025-07-17T09:14:04.858626Z","shell.execute_reply.started":"2025-07-17T09:10:25.319277Z","shell.execute_reply":"2025-07-17T09:14:04.857945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram of mask areas\n\n# This will give a biological understanding - how sick the people are\nplt.figure(figsize=(10,6))\nsns.histplot(df[df['mask_area'] > 0]['mask_area'], bins=50, kde=True)\nplt.title('Distribution of Pneumothorax Mask Areas (pixels)')\nplt.xlabel('Mask Area (pixels)')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:04.859323Z","iopub.execute_input":"2025-07-17T09:14:04.85953Z","iopub.status.idle":"2025-07-17T09:14:05.208583Z","shell.execute_reply.started":"2025-07-17T09:14:04.859514Z","shell.execute_reply":"2025-07-17T09:14:05.207985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define paths\nimage_dir = '/kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images'\nmask_dir = '/kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks'\n\n# List all mask files\nmask_files = [f for f in os.listdir(mask_dir) if f.endswith('.png')]\n\n# Pick the first mask file as an example\nsample_mask_file = mask_files[0]\n\n# The corresponding image file (assuming naming scheme is similar)\nsample_image_file = sample_mask_file.replace('_mask', '')\n\n# Load images\nimg = Image.open(os.path.join(image_dir, sample_image_file))\nmask = Image.open(os.path.join(mask_dir, sample_mask_file))\n\n# Plot\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(img, cmap='gray')\nplt.title('Chest X-ray')\n\nplt.subplot(1, 2, 2)\nplt.imshow(img, cmap='gray')\nplt.imshow(mask, cmap='Reds', alpha=0.4)\nplt.title('Overlay: Mask on Image')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:05.210394Z","iopub.execute_input":"2025-07-17T09:14:05.210605Z","iopub.status.idle":"2025-07-17T09:14:05.964006Z","shell.execute_reply.started":"2025-07-17T09:14:05.210587Z","shell.execute_reply":"2025-07-17T09:14:05.963319Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Helper Functions \n\n### Rename link masks ","metadata":{}},{"cell_type":"code","source":"%%writefile rename_link_masks.sh\n#!/bin/bash\n\nSOURCE_DIR=\"$1\"\n\nif [[ -z \"$SOURCE_DIR\" || ! -d \"$SOURCE_DIR\" ]]; then\n  echo \"Usage: $0 /path/to/source_dir\"\n  exit 1\nfi\n\nmkdir -p labelsTr labelsTs\n\nfor FILE in \"$SOURCE_DIR\"/*.png; do\n  BASENAME=$(basename \"$FILE\")\n  \n  if [[ \"$BASENAME\" == *_train_* ]]; then\n    DEST=\"labelsTr\"\n  elif [[ \"$BASENAME\" == *_test_* ]]; then\n    DEST=\"labelsTs\"\n  else\n    continue\n  fi\n\n  NEW_NAME=\"${BASENAME%.png}.png\"\n\n  ln -s \"$(realpath \"$FILE\")\" \"$DEST/$NEW_NAME\"\ndone\n\necho \"Symbolic links created in labelsTr and labelsTs.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:05.964708Z","iopub.execute_input":"2025-07-17T09:14:05.964891Z","iopub.status.idle":"2025-07-17T09:14:05.970512Z","shell.execute_reply.started":"2025-07-17T09:14:05.964876Z","shell.execute_reply":"2025-07-17T09:14:05.969674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!bash rename_link_masks.sh /kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:14:05.971317Z","iopub.execute_input":"2025-07-17T09:14:05.971523Z","iopub.status.idle":"2025-07-17T09:15:16.69735Z","shell.execute_reply.started":"2025-07-17T09:14:05.971505Z","shell.execute_reply":"2025-07-17T09:15:16.696562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Rename link\n","metadata":{}},{"cell_type":"code","source":"%%writefile rename_link.sh\n#!/bin/bash\n\nSOURCE_DIR=\"$1\"\n\nif [[ -z \"$SOURCE_DIR\" || ! -d \"$SOURCE_DIR\" ]]; then\n  echo \"Usage: $0 /path/to/source_dir\"\n  exit 1\nfi\n\nmkdir -p imagesTr imagesTs\n\nfor FILE in \"$SOURCE_DIR\"/*.png; do\n  BASENAME=$(basename \"$FILE\")\n  \n  if [[ \"$BASENAME\" == *_train_* ]]; then\n    DEST=\"imagesTr\"\n  elif [[ \"$BASENAME\" == *_test_* ]]; then\n    DEST=\"imagesTs\"\n  else\n    continue\n  fi\n\n  NEW_NAME=\"${BASENAME%.png}_0000.png\"\n\n  ln -s \"$(realpath \"$FILE\")\" \"$DEST/$NEW_NAME\"\ndone\n\necho \"Symbolic links created in imagesTr and imagesTs.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:16.698612Z","iopub.execute_input":"2025-07-17T09:15:16.69927Z","iopub.status.idle":"2025-07-17T09:15:16.704656Z","shell.execute_reply.started":"2025-07-17T09:15:16.699243Z","shell.execute_reply":"2025-07-17T09:15:16.703915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!bash rename_link.sh /kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:15:16.705492Z","iopub.execute_input":"2025-07-17T09:15:16.705686Z","iopub.status.idle":"2025-07-17T09:16:55.878448Z","shell.execute_reply.started":"2025-07-17T09:15:16.705668Z","shell.execute_reply":"2025-07-17T09:16:55.877585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Convert masks","metadata":{}},{"cell_type":"code","source":"%%writefile convert_masks.sh\n#!/bin/bash\n\nINPUT_DIR=\"$1\"\nOUTPUT_DIR=\"$2\"\n\nif [[ -z \"$INPUT_DIR\" || -z \"$OUTPUT_DIR\" ]]; then\n  echo \"Usage: $0 /path/to/input_dir /path/to/output_dir\"\n  exit 1\nfi\n\nmkdir -p \"$OUTPUT_DIR\"\n\nfor FILE in \"$INPUT_DIR\"/*.png; do\n  BASENAME=$(basename \"$FILE\")\n  OUTPUT_FILE=\"$OUTPUT_DIR/$BASENAME\"\n\n  convert \"$FILE\" -depth 8 -type Grayscale \\\n    -fx 'i==255 ? 1 : 0' \"$OUTPUT_FILE\"\ndone\n\necho \"Conversion complete. Output saved in $OUTPUT_DIR.\"\n\n!bash convert_masks.sh labelsTr labelsTr_converted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:55.87959Z","iopub.execute_input":"2025-07-17T09:16:55.879802Z","iopub.status.idle":"2025-07-17T09:16:55.88565Z","shell.execute_reply.started":"2025-07-17T09:16:55.879782Z","shell.execute_reply":"2025-07-17T09:16:55.88497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n\ninput_dir = 'labelsTr'           # folder with original masks (created by your rename_link_masks.sh)\noutput_dir = 'labelsTr_converted'  # output folder for converted masks\n\nos.makedirs(output_dir, exist_ok=True)\n\nfor filename in os.listdir(input_dir):\n    if filename.endswith('.png'):\n        mask_path = os.path.join(input_dir, filename)\n        mask = Image.open(mask_path).convert('L')  # convert to grayscale\n        \n        mask_np = np.array(mask)\n        # Convert 255 -> 1, keep 0 -> 0\n        mask_np = (mask_np == 255).astype(np.uint8)\n        \n        out_path = os.path.join(output_dir, filename)\n        Image.fromarray(mask_np).save(out_path)\n\nprint(\"Mask conversion done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:16:55.889012Z","iopub.execute_input":"2025-07-17T09:16:55.889265Z","iopub.status.idle":"2025-07-17T09:19:05.263805Z","shell.execute_reply.started":"2025-07-17T09:16:55.889246Z","shell.execute_reply":"2025-07-17T09:19:05.263076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After running this above code, your output directory should look like this:\n\n/kaggle/working/\n\n├── convert_masks.sh\n\n├── imagesTr/                 ← Training images\n\n├── imagesTs/                 ← Test images\n\n├── labelsTr/                 ← Original training masks\n\n├── labelsTr_converted/      ← Converted/renamed training masks\n\n├── labelsTs/                ← Test masks\n\n├── rename_link.sh\n\n├── rename_link_masks.sh","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------\n\n## Methodology\n\n### Tackle class imbalance via under-sampling\n\nWe are trying two approaches, one is setting up weights for undersample-representation, which will be implemented by Julia, and the other one is downsampling, which is implemented by me.\n\nBelow I am selecting random cases from under-represented sample to have 1-1 distribution in the data. This will help model not to have any biases towards the majority case (healthy people).","metadata":{}},{"cell_type":"code","source":"import os\n\nbase_path = '/kaggle/working'\n\nfolders = [\n    'imagesTr',\n    'imagesTs',\n    'labelsTr',\n    'labelsTr_converted',\n    'labelsTs'\n]\n\nfor folder in folders:\n    folder_path = os.path.join(base_path, folder)\n    print(f\"\\nExamples from folder: {folder}\")\n    try:\n        files = os.listdir(folder_path)\n        if not files:\n            print(\"  (No files found)\")\n            continue\n        for f in files[:5]:\n            print(\" \", f)\n    except FileNotFoundError:\n        print(\"  (Folder not found)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:05.264787Z","iopub.execute_input":"2025-07-17T09:19:05.265315Z","iopub.status.idle":"2025-07-17T09:19:05.291369Z","shell.execute_reply.started":"2025-07-17T09:19:05.265288Z","shell.execute_reply":"2025-07-17T09:19:05.290581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimages_dir = '/kaggle/working/imagesTr'\nmasks_dir = '/kaggle/working/labelsTr_converted'\n\n# List files\nimage_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\nmask_files = sorted([f for f in os.listdir(masks_dir) if f.endswith('.png')])\n\n# Print a few examples from each\nprint(\"Sample image filenames:\")\nfor f in image_files[:10]:\n    print(\"  \", f)\n\nprint(\"\\nSample mask filenames:\")\nfor f in mask_files[:10]:\n    print(\"  \", f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:05.292282Z","iopub.execute_input":"2025-07-17T09:19:05.292585Z","iopub.status.idle":"2025-07-17T09:19:05.317563Z","shell.execute_reply.started":"2025-07-17T09:19:05.292559Z","shell.execute_reply":"2025-07-17T09:19:05.316958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"#!pip install git+https://github.com/Project-MONAI/MONAI#egg=monai\n\n# install dependencies\n#!pip install fire nibabel\n#!pip install \"scikit-image>=0.19.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:05.318207Z","iopub.execute_input":"2025-07-17T09:19:05.31838Z","iopub.status.idle":"2025-07-17T09:19:05.321705Z","shell.execute_reply.started":"2025-07-17T09:19:05.318366Z","shell.execute_reply":"2025-07-17T09:19:05.320992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, random\nfrom pathlib import Path\nimport numpy as np\nimport torch\nfrom torch import optim, nn\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.transforms as T\nfrom tqdm import tqdm\n\n# Config\nBASE_PATH = '/kaggle/working'\nIMG_FOLDER = 'imagesTr'\nMASK_FOLDER = 'labelsTr'\nRESIZE = 256 #516\nBATCH_SIZE = 8 #32\nLR = 3e-4\nSEED = 42\nEPOCHS = 100 #100\nw_dc = 0.3 # weight of dice loss\nw_bce = 0.7 # weight of bce loss\n\n# Seed\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\ngenerator = torch.Generator().manual_seed(42)\n# Device\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Device:\", DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:05.322584Z","iopub.execute_input":"2025-07-17T09:19:05.322839Z","iopub.status.idle":"2025-07-17T09:19:15.378772Z","shell.execute_reply.started":"2025-07-17T09:19:05.322812Z","shell.execute_reply":"2025-07-17T09:19:15.378055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LungCTDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, resize=RESIZE): \n        self.image_dir = Path(image_dir)\n        self.mask_dir = Path(mask_dir)\n        self.files = sorted([f.name for f in self.image_dir.iterdir() if f.suffix == '.png'])\n        tf = T.Compose([T.Resize((resize, resize)), T.ToTensor()])\n        self.img_tf, self.mask_tf = tf, tf\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_name = self.files[idx]\n        mask_name = img_name.replace('__0000.png', '_.png')\n        img = Image.open(self.image_dir / img_name).convert('L')\n        mask = Image.open(self.mask_dir / mask_name).convert('L')\n        img, mask = self.img_tf(img), self.mask_tf(mask)\n        return img, (mask > 0).float()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:15.379631Z","iopub.execute_input":"2025-07-17T09:19:15.380097Z","iopub.status.idle":"2025-07-17T09:19:15.386256Z","shell.execute_reply.started":"2025-07-17T09:19:15.380075Z","shell.execute_reply":"2025-07-17T09:19:15.385521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.dc1 = DownSample(in_channels, 64)\n        self.dc2 = DownSample(64, 128)\n        self.dc3 = DownSample(128, 256)\n        self.dc4 = DownSample(256, 512)\n\n        self.bn = DoubleConv(512, 1024) # bottleneck\n\n        self.uc1 = UpSample(1024, 512)\n        self.uc2 = UpSample(512, 256)\n        self.uc3 = UpSample(256, 128)\n        self.uc4 = UpSample(128, 64)\n\n        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n\n    def forward(self, x):\n       down_1, p1 = self.dc1(x)\n       down_2, p2 = self.dc2(p1)\n       down_3, p3 = self.dc3(p2)\n       down_4, p4 = self.dc4(p3)\n\n       b = self.bn(p4) # bottleneck\n\n       up_1 = self.uc1(b, down_4)\n       up_2 = self.uc2(up_1, down_3)\n       up_3 = self.uc3(up_2, down_2)\n       up_4 = self.uc4(up_3, down_1)\n\n       out = self.out(up_4)\n       return out\n\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv_op = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv_op(x)\n\nclass DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        down = self.conv(x)\n        p = self.pool(down)\n\n        return down, p\n\nclass UpSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n       x1 = self.up(x1)\n       x = torch.cat([x1, x2], 1)\n       return self.conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:15.38698Z","iopub.execute_input":"2025-07-17T09:19:15.387241Z","iopub.status.idle":"2025-07-17T09:19:15.410624Z","shell.execute_reply.started":"2025-07-17T09:19:15.387212Z","shell.execute_reply":"2025-07-17T09:19:15.409865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_coefficient(p, t, epsilon=1e-07):\n    p_copy = p.clone()\n\n    p_copy[p_copy < 0.5] = 0\n    p_copy[p_copy > 0.5] = 1\n\n    intersection = abs(torch.sum(p_copy * t))\n    union = abs(torch.sum(p_copy) + torch.sum(t))\n    dice = (2 * intersection + epsilon) / (union + epsilon)\n    \n    return dice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:15.411346Z","iopub.execute_input":"2025-07-17T09:19:15.411583Z","iopub.status.idle":"2025-07-17T09:19:15.430307Z","shell.execute_reply.started":"2025-07-17T09:19:15.411567Z","shell.execute_reply":"2025-07-17T09:19:15.429552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def iou_coefficient(p, t, epsilon=1e-8):\n    p_copy = p.clone()\n\n    p_copy[p_copy  < 0.5] = 0\n    p_copy[p_copy  > 0.5] = 1\n\n    intersection = abs(torch.sum(p_copy * t))\n    union = abs(torch.sum(p_copy) + torch.sum(t))\n    iou = (intersection + epsilon) / ((union + epsilon)-intersection)\n    \n    return iou","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_epoch_with_metrics(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_dice = 0\n    total_iou = 0\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            total_loss += criterion(pred, y).item()\n            total_dice += dice_coefficient(pred, y).item()\n            total_iou += iou_coefficient(pred, y).item()\n\n            # Save predictions and labels for AUC calculation later\n            all_preds.extend(pred.view(-1).cpu().numpy())\n            all_labels.extend(y.view(-1).cpu().numpy())\n\n    # Calculate pixel-wise ROC AUC\n    from sklearn.metrics import roc_auc_score\n    auc = roc_auc_score(all_labels, all_preds)\n\n    n = len(loader)\n    return total_loss / n, total_dice / n, total_iou / n, auc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    total = 0\n    for X, y in tqdm(loader, desc=\"Train\", leave=False):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = criterion(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total += loss.item()\n    return total / len(loader)\n\ndef eval_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_dice = 0\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            total_loss += criterion(pred, y).item()\n            total_dice += dice_coefficient(pred, y).item()\n    return total_loss / len(loader), total_dice / len(loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_dir = Path(BASE_PATH) / IMG_FOLDER\nmask_dir = Path(BASE_PATH) / MASK_FOLDER\n\n#train_losses = []\n#train_dcs = []\n#val_losses = []\n#val_dcs = []\n\ntrain_losses = []\nval_losses = []\nval_dices = []\nval_ious = []\nval_aucs = []\n\nbest_dice = 0\n\ndataset = LungCTDataset(img_dir, mask_dir, resize=RESIZE)\ntrain_len = int(0.8 * len(dataset)) ###adjusted\ntest_len = len(dataset) - train_len\ntrain_ds, test_ds = random_split(dataset, [train_len, test_len], generator = torch.Generator().manual_seed(SEED))\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\nmodel = UNet(in_channels=1, num_classes=1).to(DEVICE)\noptimizer = optim.AdamW(model.parameters(), lr=LR)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.0]).to(DEVICE)) # weights; best so far: 5\n\nfor epoch in range(1, EPOCHS + 1):\n    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n    val_loss, val_dice, val_iou, val_auc = eval_epoch_with_metrics(model, test_loader, criterion, DEVICE)\n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Dice: {val_dice:.4f} | IoU: {val_iou:.4f} | AUC: {val_auc:.4f}\")\n\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    val_dices.append(val_dice)\n    val_ious.append(val_iou)\n    val_aucs.append(val_auc)\n\n    if val_dice > best_dice:\n        best_dice = val_dice\n        torch.save(model.state_dict(), 'unett_lung_seg.pt')\n        print(f\"✔ Best model saved (Dice {best_dice:.4f})\")\n\ntorch.save({\n    'epoch': EPOCHS,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'dice': best_dice\n}, 'unett_lung_seg_last.pt')\nprint(\"✅ Training complete! Best Dice:\", best_dice)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:19:15.431056Z","iopub.execute_input":"2025-07-17T09:19:15.431269Z","iopub.status.idle":"2025-07-17T09:30:33.22066Z","shell.execute_reply.started":"2025-07-17T09:19:15.431254Z","shell.execute_reply":"2025-07-17T09:30:33.219504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Result Plot","metadata":{}},{"cell_type":"code","source":"# Plot metrics\nimport matplotlib.pyplot as plt\n\nepochs = range(1, EPOCHS + 1)\n\nplt.figure(figsize=(14, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, train_losses, label='Train Loss')\nplt.plot(epochs, val_losses, label='Val Loss')\nplt.title('Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, val_dices, label='Val Dice')\nplt.title('Dice Coefficient')\nplt.xlabel('Epoch')\nplt.ylabel('Dice')\nplt.legend()\n\nplt.subplot(2, 2, 3)\nplt.plot(epochs, val_ious, label='Val IoU')\nplt.title('Intersection over Union (IoU)')\nplt.xlabel('Epoch')\nplt.ylabel('IoU')\nplt.legend()\n\nplt.subplot(2, 2, 4)\nplt.plot(epochs, val_aucs, label='Val AUC')\nplt.title('Pixel-wise ROC AUC')\nplt.xlabel('Epoch')\nplt.ylabel('AUC')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:30:33.221467Z","iopub.status.idle":"2025-07-17T09:30:33.22212Z","shell.execute_reply.started":"2025-07-17T09:30:33.221981Z","shell.execute_reply":"2025-07-17T09:30:33.221999Z"}},"outputs":[],"execution_count":null}]}